{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbe1cf81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e7c12eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HF_HOME: /home/hice1/kpereira6/scratch/ConvAI/hf_cache\n",
      "HF_DATASETS_CACHE: /home/hice1/kpereira6/scratch/ConvAI/hf_cache\n",
      "TRANSFORMERS_CACHE: /home/hice1/kpereira6/scratch/ConvAI/hf_cache\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Set environment variables\n",
    "#might wanna change this\n",
    "os.environ[\"HF_HOME\"] = \"/home/hice1/kpereira6/scratch/ConvAI/hf_cache\"\n",
    "os.environ[\"HF_DATASETS_CACHE\"] = \"/home/hice1/kpereira6/scratch/ConvAI/hf_cache\"\n",
    "os.environ[\"TRANSFORMERS_CACHE\"] = \"/home/hice1/kpereira6/scratch/ConvAI/hf_cache\"\n",
    "\n",
    "# Verify the variables (optional)\n",
    "print(\"HF_HOME:\", os.environ.get(\"HF_HOME\"))\n",
    "print(\"HF_DATASETS_CACHE:\", os.environ.get(\"HF_DATASETS_CACHE\"))\n",
    "print(\"TRANSFORMERS_CACHE:\", os.environ.get(\"TRANSFORMERS_CACHE\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df0eb05a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hice1/kpereira6/.conda/envs/cAI8803-gpu/lib/python3.10/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afc97eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import BertModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb6cfe66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining model arch\n",
    "\n",
    "class MultiTurnToxicityModelLSTM(nn.Module):\n",
    "    def __init__(self, bert_model_name='bert-base-uncased', hidden_dim=768, lstm_hidden_dim=512, num_layers=1, dropout_rate=0.3):\n",
    "        super(MultiTurnToxicityModelLSTM, self).__init__()\n",
    "\n",
    "        # Load pretrained BERT\n",
    "        self.bert = BertModel.from_pretrained(bert_model_name)\n",
    "\n",
    "        # Freeze BERT layers if you do not want to train them\n",
    "        for param in self.bert.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        # LSTM to model multi-turn context\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=hidden_dim,\n",
    "            hidden_size=lstm_hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout_rate if num_layers > 1 else 0  # Apply dropout only if more than one layer\n",
    "        )\n",
    "\n",
    "        # Fully connected layer for toxicity classification\n",
    "        self.fc = nn.Linear(lstm_hidden_dim, 1)\n",
    "\n",
    "        # Sigmoid activation for binary classification\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, tokenized_turns, attention_masks):\n",
    "        turn_embeddings = []\n",
    "\n",
    "        # Process each turn independently using BERT\n",
    "        for i in range(len(tokenized_turns)):\n",
    "            outputs = self.bert(input_ids=tokenized_turns[i], attention_mask=attention_masks[i])\n",
    "            cls_embedding = outputs.last_hidden_state[:, 0, :]  # CLS token embedding for each turn\n",
    "            turn_embeddings.append(cls_embedding)\n",
    "\n",
    "        # Stack the turn embeddings (batch_size, num_turns, hidden_dim)\n",
    "        turn_embeddings = torch.stack(turn_embeddings, dim=0)\n",
    "\n",
    "        # Pass the embeddings through the LSTM\n",
    "        lstm_output, (hidden, _) = self.lstm(turn_embeddings)  # hidden: (num_layers, batch_size, lstm_hidden_dim)\n",
    "\n",
    "        # Use the hidden state of the last LSTM layer for classification\n",
    "        final_hidden_state = hidden[-1]  # (batch_size, lstm_hidden_dim)\n",
    "\n",
    "        # Final classification layer to predict toxicity of the last bot turn\n",
    "        logits = self.fc(final_hidden_state)  # (batch_size, 1)\n",
    "        return self.sigmoid(logits)  # Output probability of toxicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "24aa0573",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "def classify_toxicity(conversation, model, tokenizer, max_turns=10, max_length=128, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Classify a conversation as toxic or non-toxic.\n",
    "\n",
    "    Args:\n",
    "        conversation (list of str): A list of alternating user and bot turns.\n",
    "        model (nn.Module): The trained MultiTurnToxicityModelLSTM model.\n",
    "        tokenizer (BertTokenizer): The BERT tokenizer.\n",
    "        max_turns (int): Maximum number of turns to consider.\n",
    "        max_length (int): Maximum token length per turn.\n",
    "        threshold (float): Threshold for classifying as toxic (default 0.5).\n",
    "\n",
    "    Returns:\n",
    "        int: 0 for non-toxic, 1 for toxic.\n",
    "    \"\"\"\n",
    "    # Ensure the conversation has exactly `max_turns`\n",
    "    if len(conversation) < max_turns:\n",
    "        conversation = [\"\"] * (max_turns - len(conversation)) + conversation\n",
    "    else:\n",
    "        conversation = conversation[-max_turns:]\n",
    "\n",
    "    # Tokenize each turn\n",
    "    tokenized_turns = []\n",
    "    attention_masks = []\n",
    "\n",
    "    for turn in conversation:\n",
    "        encoded = tokenizer(turn, padding='max_length', truncation=True, max_length=max_length, return_tensors=\"pt\")\n",
    "        tokenized_turns.append(encoded['input_ids'].squeeze(0))  # shape (max_length,)\n",
    "        attention_masks.append(encoded['attention_mask'].squeeze(0))  # shape (max_length,)\n",
    "\n",
    "    # Convert lists of tensors to tensors of shape (1, num_turns, max_length)\n",
    "    tokenized_turns = torch.stack(tokenized_turns).unsqueeze(0)  # Add batch dimension\n",
    "    attention_masks = torch.stack(attention_masks).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "    # Forward pass through the model\n",
    "    model.eval()  # Ensure the model is in evaluation mode\n",
    "    with torch.no_grad():\n",
    "        prediction = model(tokenized_turns, attention_masks)\n",
    "\n",
    "    # Classify based on threshold\n",
    "    toxicity_probability = prediction.item()\n",
    "    return toxicity_probability \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a4e43ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/1033168/ipykernel_830136/2464930357.py:19: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(checkpoint_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toxicity classification: 0.343756765127182 (0: Non-toxic, 1: Toxic)\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Example conversation\n",
    "    example_conversation = [\n",
    "             \"USER: If arrested blame it on the pokemon you were trying to catch while driving\",\n",
    "            \"BOT: Not like driving makes them go faster or anything\",\n",
    "            \"USER: Notice the quotations.hey Trump you play Pokemon go???I wish I had time. Next question.HEADLINE!!!! TRUMP WISHES HE HAD TIME TO PLAY POKEMON. HE LOVES IT\",\n",
    "            \"BOT: You'll be fined for using that meme!\",\n",
    "            \"I WILL BOMB YOU\"\n",
    "    ]\n",
    "\n",
    "    # Load the tokenizer and model\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "    model = MultiTurnToxicityModelLSTM(bert_model_name='bert-base-uncased')\n",
    "\n",
    "    # Load the trained model weights\n",
    "    #path to checkpoint\n",
    "    checkpoint_path = \"/home/hice1/kpereira6/scratch/ConvAI/Eval/best_model_lstm.pth\" \n",
    "    model.load_state_dict(torch.load(checkpoint_path))\n",
    "\n",
    "    # Classify the conversation\n",
    "    result = classify_toxicity(example_conversation, model, tokenizer)\n",
    "    print(f\"Toxicity classification: {result} (0: Non-toxic, 1: Toxic)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28205e30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-cAI8803-gpu]",
   "language": "python",
   "name": "conda-env-.conda-cAI8803-gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
